{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for project: \"miRNA Biomarker for Lung Cancer Diagnostics - Selecting a test panel for patient classification -\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:24:45.574220Z",
     "start_time": "2020-05-14T17:24:44.291178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/P_Neubert/Anaconda/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import all Packages & Modules\n",
    "\n",
    "# IPython\n",
    "from IPython.display import Image\n",
    "\n",
    "# mlxtend\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz  \n",
    "\n",
    "# subprocess\n",
    "from subprocess import call\n",
    "\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# yellowbrick\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# missingno\n",
    "import missingno\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# pickle (for saving and loading data)\n",
    "import pickle # \n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# sys (enables to exit execution of code)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:49:29.198985Z",
     "start_time": "2020-05-14T16:49:29.196023Z"
    }
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:24:45.587188Z",
     "start_time": "2020-05-14T17:24:45.577269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all written Functions\n",
    "\n",
    "from functions import feature_selection\n",
    "from functions import rfe_selection\n",
    "from functions import dataframe_selection\n",
    "from functions import model_evaluation\n",
    "from functions import top_model\n",
    "from functions import multibar_plot\n",
    "from functions import random_searching\n",
    "from functions import grid_searching\n",
    "from functions import viz_summary\n",
    "from functions import feature_reduce\n",
    "from functions import score_eval\n",
    "from functions import heatmap\n",
    "from functions import TOP_n_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:48:16.844405Z",
     "start_time": "2020-05-14T16:48:16.841306Z"
    }
   },
   "source": [
    "### Prerequesites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:24:45.596778Z",
     "start_time": "2020-05-14T17:24:45.590925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random_state seed to exclude for randomness effects in the notebook\n",
    "seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:24:45.610513Z",
     "start_time": "2020-05-14T17:24:45.600506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load all necessary dataframes from main notebook\n",
    "# for Random Search and Grid Search to be used in this notebook\n",
    "X_tbc_top20 = pd.read_pickle(\"data/X_tbc_top20\")\n",
    "y_train = pd.read_pickle(\"data/y_train\")\n",
    "X_tbc_top20_test = pd.read_pickle(\"data/X_tbc_top20_test\")\n",
    "y_test = pd.read_pickle(\"data/y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:57:44.704516Z",
     "start_time": "2020-05-14T16:57:44.701543Z"
    }
   },
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I know which Feature Selection in combination with which classification model performs best, I try to **optimize on the chosen metric precision** (described in the main notebook). As the ranking might change I use the TOP3 models (RFC, ETC, XGBC) in combination with the Feature Selection of TOP20 Combination of tree-based Classifier (TOP20 TBC) for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T10:47:58.400282Z",
     "start_time": "2020-05-14T17:51:56.453Z"
    }
   },
   "source": [
    "### Optimization of parameters with Random Search & Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Grid Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the the whole Random Search and Grid Search process takes approxemately 8 hours to compute, I decided to outsource this part of code to this seperate notebook.\n",
    "\n",
    "I always include the default values of the models in the hyperparameter grid in case this would be already the best conditions for my dataset. In this way it is also easier to compare with the unoptimized model.\n",
    "\n",
    "First I perform a Randomized Search to check a broad range of model parameters. This search method is quick by using only random combinations and no cross validation limited to 500 fits. In this way I can narrow down the parameters for a more detailed optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:24:45.621357Z",
     "start_time": "2020-05-14T17:24:45.614576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Classifier Models\n",
    "RFC2 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "ETC2 = ExtraTreesClassifier(random_state=seed, n_jobs=-1)\n",
    "XGBC2 = XGBClassifier(random_state=seed, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Search Random Forrest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:31:28.657975Z",
     "start_time": "2020-05-14T17:24:45.624507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8333333333333334\n",
      "Roc_AUC score Unoptimized: 0.9801128428579409\n",
      "Precision score Unoptimized: 0.8333333333333334\n",
      "F1 score Unoptimized: 0.8333333333333334\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8333333333333334\n",
      "Roc_AUC score Optimized: 0.9816909669850847\n",
      "Precision score Optimized: 0.8333333333333334\n",
      "F1 score Optimized: 0.8333333333333334\n",
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=10, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
      "                       n_jobs=-1, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_RFC = {\n",
    "    'bootstrap': [True, False], # default=True\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 3, 5, 10], # default=2\n",
    "    'n_estimators': [100, 400, 700, 1000, 1300, 1600], # default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(RFC2, parameters_RFC, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:39:43.715997Z",
     "start_time": "2020-05-14T17:31:28.660757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8333333333333334\n",
      "Roc_AUC score Unoptimized: 0.9801128428579409\n",
      "Precision score Unoptimized: 0.8333333333333334\n",
      "F1 score Unoptimized: 0.8333333333333334\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8333333333333334\n",
      "Roc_AUC score Optimized: 0.9801477571085414\n",
      "Precision score Optimized: 0.8333333333333334\n",
      "F1 score Optimized: 0.8333333333333334\n",
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1400,\n",
      "                       n_jobs=-1, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Second use random search to further narrow down the range of parameters\n",
    "\n",
    "# Set a new Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_RFC_new = {\n",
    "    'bootstrap': [True, False], # default=True\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 6, 8, 10, 12, 14], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9], # default=2\n",
    "    'n_estimators': [100, 1100, 1200, 1300, 1400, 1500], # default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(RFC2, parameters_RFC_new, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:01:51.479567Z",
     "start_time": "2020-05-14T17:01:51.476276Z"
    }
   },
   "source": [
    "##### Random Search Extra Tree Classifier (ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:45:44.877385Z",
     "start_time": "2020-05-14T17:39:43.721934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8666666666666667\n",
      "Roc_AUC score Unoptimized: 0.9847424724875705\n",
      "Precision score Unoptimized: 0.8666666666666667\n",
      "F1 score Unoptimized: 0.8666666666666667\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8666666666666667\n",
      "Roc_AUC score Optimized: 0.984777386738171\n",
      "Precision score Optimized: 0.8666666666666667\n",
      "F1 score Optimized: 0.8666666666666667\n",
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=10, max_features='sqrt',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=1600, n_jobs=-1,\n",
      "                     oob_score=False, random_state=1, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_ETC = {\n",
    "    'bootstrap': [False, True], # default=False\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 5, 10], # default=2\n",
    "    'n_estimators': [100, 400, 800, 1200, 1600, 2000], # default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(ETC2, parameters_ETC, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:48:16.878893Z",
     "start_time": "2020-05-14T17:45:44.881213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8666666666666667\n",
      "Roc_AUC score Unoptimized: 0.9847424724875705\n",
      "Precision score Unoptimized: 0.8666666666666667\n",
      "F1 score Unoptimized: 0.8666666666666667\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8666666666666667\n",
      "Roc_AUC score Optimized: 0.9832341768616278\n",
      "Precision score Optimized: 0.8666666666666667\n",
      "F1 score Optimized: 0.8666666666666667\n",
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=28, max_features='log2',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=4,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "                     oob_score=False, random_state=1, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Second use random search to further narrow down the range of parameters\n",
    "\n",
    "# Set a new Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_ETC_new = {\n",
    "    'bootstrap': [False, True], # default=False\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 26, 28, 30, 32, 34], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 3, 4], # default=2\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600], # default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(ETC2, parameters_ETC_new, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:02:40.363559Z",
     "start_time": "2020-05-14T17:02:40.360498Z"
    }
   },
   "source": [
    "##### Random Search XG Boost Classifier (XGBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:49:47.694192Z",
     "start_time": "2020-05-14T17:48:16.881714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.9\n",
      "Roc_AUC score Unoptimized: 0.9878288922406568\n",
      "Precision score Unoptimized: 0.9\n",
      "F1 score Unoptimized: 0.9\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8666666666666667\n",
      "Roc_AUC score Optimized: 0.9907756549913413\n",
      "Precision score Optimized: 0.8666666666666667\n",
      "F1 score Optimized: 0.8666666666666667\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.75, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=21,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
      "              nthread=None, objective='multi:softprob', random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=0.7, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_XGBC = {\n",
    "    'max_depth': [3, 9, 15, 21, 27, 33, None], # default=3\n",
    "    'learning_rate': [0.1, 0.01, 0.001, 0.0001], # default=0.1\n",
    "    'min_child_weight': [1, 2, 3], # default=1\n",
    "    'subsample': [1.0, 0.9, 0.8, 0.7, 0.6], # default=1.0\n",
    "    'colsample_bytree': [1.0, 0.75, 0.5], # default=1.0\n",
    "    'n_estimators': [100, 200, 300, 400, 500], #default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(XGBC2, parameters_XGBC, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:51:15.913874Z",
     "start_time": "2020-05-14T17:49:47.698953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.9\n",
      "Roc_AUC score Unoptimized: 0.9878288922406568\n",
      "Precision score Unoptimized: 0.9\n",
      "F1 score Unoptimized: 0.9\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8\n",
      "Roc_AUC score Optimized: 0.9876892352382548\n",
      "Precision score Optimized: 0.8\n",
      "F1 score Optimized: 0.8000000000000002\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.45, gamma=0,\n",
      "              learning_rate=0.005, max_delta_step=0, max_depth=36,\n",
      "              min_child_weight=1, missing=None, n_estimators=250, n_jobs=-1,\n",
      "              nthread=None, objective='multi:softprob', random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=0.95, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Second use random search to further narrow down the range of parameters\n",
    "\n",
    "# Set a new Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_XGBC_new = {\n",
    "    'max_depth': [3, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], # default=3\n",
    "    'learning_rate': [0.1, 0.005, 0.0075, 0.01, 0.025, 0.05], # default=0.1\n",
    "    'min_child_weight': [1, 2, 3], # default=1\n",
    "    'subsample': [1.0, 0.85, 0.875, 0.9, 0.925, 0.95], # default=1.0\n",
    "    'colsample_bytree': [1.0, 0.45, 0.475, 0.5, 0.525, 0.55], # default=1.0\n",
    "    'n_estimators': [100, 225, 250, 300, 325, 350], #default=100\n",
    "}\n",
    "\n",
    "# Use random_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test, y_test)\n",
    "random_searching(XGBC2, parameters_XGBC_new, X_tbc_top20, y_train, X_tbc_top20_test, y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:51:15.924190Z",
     "start_time": "2020-05-14T17:51:15.919145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stop Switch (comment out to run the steps below)\n",
    "# sys.exit(\"Stop without Grid Search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:03:56.524080Z",
     "start_time": "2020-05-14T17:03:56.520027Z"
    }
   },
   "source": [
    "#### Optimization of parameters with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After narrowing down the model parameters with Randomized Search, I can use the reduced set for the more exact method GridSearchCV. This algorithm uses all possible parameters and evaluates them in detail with cross-validation not limited to a number of fits. In that way the best parameters are optimized on precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:51:15.936988Z",
     "start_time": "2020-05-14T17:51:15.927735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Classifier Models\n",
    "RFC3 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "ETC3 = ExtraTreesClassifier(random_state=seed, n_jobs=-1)\n",
    "XGBC3 = XGBClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "# Create Dictionary for Optimization results\n",
    "results_opt = {}\n",
    "\n",
    "# Lists with keys for optimized and unoptized models\n",
    "name_model_RFC = [\"RFC_UnOpt\", \"RFC_Opt\"]\n",
    "name_model_ETC = [\"ETC_UnOpt\", \"ETC_Opt\"]\n",
    "name_model_XGBC = [\"XGBC_UnOpt\", \"XGBC_Opt\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search Random Forrest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T19:32:34.784298Z",
     "start_time": "2020-05-14T17:51:15.940760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 60.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 66.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 74.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 91.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 101.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed: 101.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8333333333333334\n",
      "Roc_AUC score Unoptimized: 0.9801128428579409\n",
      "Precision score Unoptimized: 0.8333333333333334\n",
      "F1 score Unoptimized: 0.8333333333333334\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8333333333333334\n",
      "Roc_AUC score Optimized: 0.9862158538629128\n",
      "Precision score Optimized: 0.8333333333333334\n",
      "F1 score Optimized: 0.8333333333333334\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=9, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1350,\n",
      "                       n_jobs=-1, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_RFC = {\n",
    "    'bootstrap': [True, False], # default=True\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 9, 10, 11], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 3, 4], # default=2\n",
    "    'n_estimators': [100, 1350, 1400, 1425, 1450], # default=100\n",
    "}\n",
    "\n",
    "# Use grid_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test)\n",
    "grid_searching(results_opt, RFC3, name_model_RFC, parameters_RFC, X_tbc_top20, y_train, X_tbc_top20_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search Extra Tree Classifier (ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T21:48:13.684697Z",
     "start_time": "2020-05-14T19:32:34.786793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 88.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 93.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 98.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 103.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 110.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 118.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 127.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8640 out of 8640 | elapsed: 135.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.8666666666666667\n",
      "Roc_AUC score Unoptimized: 0.9847424724875705\n",
      "Precision score Unoptimized: 0.8666666666666667\n",
      "F1 score Unoptimized: 0.8666666666666667\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8666666666666667\n",
      "Roc_AUC score Optimized: 0.9817607954862857\n",
      "Precision score Optimized: 0.8666666666666667\n",
      "F1 score Optimized: 0.8666666666666667\n",
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='sqrt',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=4,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=-1,\n",
      "                     oob_score=False, random_state=1, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_ETC = {\n",
    "    'bootstrap': [False, True], # default=False\n",
    "    'criterion': ['gini', 'entropy'], # default=gini\n",
    "    'max_depth': [None, 25, 26, 27], # default=None\n",
    "    'max_features': ['sqrt', 'log2'], # default=sqrt\n",
    "    'min_samples_leaf': [1, 2, 3], # default=1\n",
    "    'min_samples_split': [2, 3, 4], # default=2\n",
    "    'n_estimators': [100, 325, 350, 400, 425, 450], # default=100\n",
    "}\n",
    "\n",
    "# Use grid_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test)\n",
    "grid_searching(results_opt, ETC3, name_model_ETC, parameters_ETC, X_tbc_top20, y_train, X_tbc_top20_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search XG Boost Classifier (XGBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T10:47:56.431098Z",
     "start_time": "2020-05-14T21:48:13.690611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15552 candidates, totalling 77760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 50.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 57.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8704 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9514 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 77.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 84.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12160 tasks      | elapsed: 92.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 99.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14104 tasks      | elapsed: 103.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15130 tasks      | elapsed: 106.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 145.4min\n",
      "[Parallel(n_jobs=-1)]: Done 17290 tasks      | elapsed: 308.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18424 tasks      | elapsed: 464.8min\n",
      "[Parallel(n_jobs=-1)]: Done 19594 tasks      | elapsed: 476.5min\n",
      "[Parallel(n_jobs=-1)]: Done 20800 tasks      | elapsed: 509.5min\n",
      "[Parallel(n_jobs=-1)]: Done 22042 tasks      | elapsed: 513.2min\n",
      "[Parallel(n_jobs=-1)]: Done 23320 tasks      | elapsed: 517.5min\n",
      "[Parallel(n_jobs=-1)]: Done 24634 tasks      | elapsed: 521.5min\n",
      "[Parallel(n_jobs=-1)]: Done 25984 tasks      | elapsed: 526.0min\n",
      "[Parallel(n_jobs=-1)]: Done 27370 tasks      | elapsed: 529.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 533.7min\n",
      "[Parallel(n_jobs=-1)]: Done 30250 tasks      | elapsed: 540.8min\n",
      "[Parallel(n_jobs=-1)]: Done 31744 tasks      | elapsed: 547.5min\n",
      "[Parallel(n_jobs=-1)]: Done 33274 tasks      | elapsed: 554.6min\n",
      "[Parallel(n_jobs=-1)]: Done 34840 tasks      | elapsed: 562.2min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 570.3min\n",
      "[Parallel(n_jobs=-1)]: Done 38080 tasks      | elapsed: 578.0min\n",
      "[Parallel(n_jobs=-1)]: Done 39754 tasks      | elapsed: 585.1min\n",
      "[Parallel(n_jobs=-1)]: Done 41464 tasks      | elapsed: 591.1min\n",
      "[Parallel(n_jobs=-1)]: Done 43210 tasks      | elapsed: 600.9min\n",
      "[Parallel(n_jobs=-1)]: Done 44992 tasks      | elapsed: 610.2min\n",
      "[Parallel(n_jobs=-1)]: Done 46810 tasks      | elapsed: 619.6min\n",
      "[Parallel(n_jobs=-1)]: Done 48664 tasks      | elapsed: 629.2min\n",
      "[Parallel(n_jobs=-1)]: Done 50554 tasks      | elapsed: 639.2min\n",
      "[Parallel(n_jobs=-1)]: Done 52480 tasks      | elapsed: 648.7min\n",
      "[Parallel(n_jobs=-1)]: Done 54442 tasks      | elapsed: 655.8min\n",
      "[Parallel(n_jobs=-1)]: Done 56440 tasks      | elapsed: 667.0min\n",
      "[Parallel(n_jobs=-1)]: Done 58474 tasks      | elapsed: 678.3min\n",
      "[Parallel(n_jobs=-1)]: Done 60544 tasks      | elapsed: 689.8min\n",
      "[Parallel(n_jobs=-1)]: Done 62650 tasks      | elapsed: 701.3min\n",
      "[Parallel(n_jobs=-1)]: Done 64792 tasks      | elapsed: 713.0min\n",
      "[Parallel(n_jobs=-1)]: Done 66970 tasks      | elapsed: 720.7min\n",
      "[Parallel(n_jobs=-1)]: Done 69184 tasks      | elapsed: 732.7min\n",
      "[Parallel(n_jobs=-1)]: Done 71434 tasks      | elapsed: 744.8min\n",
      "[Parallel(n_jobs=-1)]: Done 73720 tasks      | elapsed: 757.2min\n",
      "[Parallel(n_jobs=-1)]: Done 76042 tasks      | elapsed: 769.6min\n",
      "[Parallel(n_jobs=-1)]: Done 77760 out of 77760 | elapsed: 779.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score Unoptimized: 0.9\n",
      "Roc_AUC score Unoptimized: 0.9878288922406568\n",
      "Precision score Unoptimized: 0.9\n",
      "F1 score Unoptimized: 0.9\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Accuracy score Optimized: 0.8333333333333334\n",
      "Roc_AUC score Optimized: 0.9876543209876543\n",
      "Precision score Optimized: 0.8333333333333334\n",
      "F1 score Optimized: 0.8333333333333334\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.45, gamma=0,\n",
      "              learning_rate=0.0075, max_delta_step=0, max_depth=31,\n",
      "              min_child_weight=1, missing=None, n_estimators=225, n_jobs=-1,\n",
      "              nthread=None, objective='multi:softprob', random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=0.88, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameter grid for Model with alternatives to default values (included in grid)\n",
    "parameters_XGBC = {\n",
    "    'max_depth': [3, 31, 32, 33], # default=3\n",
    "    'learning_rate': [0.1, 0.0065, 0.007, 0.0075, 0.008, 0.0085], # default=0.1\n",
    "    'min_child_weight': [1, 2, 3], # default=1\n",
    "    'subsample': [1.0, 0.88, 0.89, 0.9, 0.91, 0.92], # default=1.0\n",
    "    'colsample_bytree': [1.0, 0.43, 0.44, 0.45, 0.46, 0.47], # default=1.0\n",
    "    'n_estimators': [100, 215, 220, 225, 230, 335], #default=100\n",
    "}\n",
    "\n",
    "# Use grid_searching function with with TOP20 TBC Features Dataset (X_tbc_top20, y_train, X_tbc_top20_test)\n",
    "grid_searching(results_opt, XGBC3, name_model_XGBC, parameters_XGBC, X_tbc_top20, y_train, X_tbc_top20_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T10:47:56.535150Z",
     "start_time": "2020-05-15T10:47:56.447086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFC_UnOpt</th>\n",
       "      <th>RFC_Opt</th>\n",
       "      <th>ETC_UnOpt</th>\n",
       "      <th>ETC_Opt</th>\n",
       "      <th>XGBC_UnOpt</th>\n",
       "      <th>XGBC_Opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_AUC</th>\n",
       "      <td>0.980113</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.981761</td>\n",
       "      <td>0.987829</td>\n",
       "      <td>0.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RFC_UnOpt   RFC_Opt  ETC_UnOpt   ETC_Opt  XGBC_UnOpt  XGBC_Opt\n",
       "Accuracy    0.833333  0.833333   0.866667  0.866667    0.900000  0.833333\n",
       "Roc_AUC     0.980113  0.986216   0.984742  0.981761    0.987829  0.987654\n",
       "Precision   0.833333  0.833333   0.866667  0.866667    0.900000  0.833333\n",
       "F1          0.833333  0.833333   0.866667  0.866667    0.900000  0.833333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe with results_optimization\n",
    "results_optimization = pd.DataFrame(results_opt)\n",
    "results_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T10:47:56.561461Z",
     "start_time": "2020-05-15T10:47:56.546827Z"
    }
   },
   "outputs": [],
   "source": [
    "# save results_opt dictionary to results_opt.p file to be used in main notebook\n",
    "with open('data/results_opt.p', 'wb') as fp:\n",
    "    pickle.dump(results_opt, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:11:50.897606Z",
     "start_time": "2020-05-14T17:11:50.893131Z"
    }
   },
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I optimized all models on precision the best way to compare their performance is by their Roc AUC score.\n",
    "\n",
    "As the Roc (receiver operating characteristics) curve of a model is the plot of the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings, this is a measure for  the overall performance of a model independent from threshold settings. For better comparision the area under the curve (AUC) is used. The bigger the better the performance.\n",
    "\n",
    "The best Roc_AUC is demonstrated by the unoptimzed XG Boost Classifier (XGBC_UnOpt; Roc_AUC: 0.987829, Rank = 6.0), followed by the optimized XG Boost Classifier (XGBC_Opt; Roc_AUC: 0.987654, Rank = 5.0).\n",
    "\n",
    "Even if the unoptimized model XGBC_UnOpt shows better performance than the optimized model XGBC_Opt, the \"true top model\" is XGBC_Opt. The reason is that during the optimization process with GridSearchCV the model is cross-validated which should prevent overfitting. The data of XGBC_UnOpt wasnt evaluated by cross-validation and might perform only better because of overfitting the data. Also I included the default parameters used by the unoptimized model in the GridSearchCV and theses resulted a worse score with cross-validation as not choosen from the algorithm as the best model parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
